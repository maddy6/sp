
import pandas as pd
import numpy as np

# --- Convert PERIOD (YYYYMM) to proper datetime ---
df['PERIOD'] = pd.to_datetime(df['PERIOD'].astype(str), format='%Y%m')
df['YEAR'] = df['PERIOD'].dt.year

# --- Forecast index (if needed) ---
forecast_index = pd.date_range(start=FORECAST_START, end=FORECAST_END, freq="MS")
groups = df['BUSINESS_GROUPS_TA'].unique()

all_rows = []

# --- Parameters ---
ROLL_WINDOW = 3    # example rolling window
alpha_wilder = 1 / ROLL_WINDOW

# --- Define Zero Lag EMA ---
def zlema(series, period):
    ema1 = series.ewm(span=period, adjust=False).mean()
    lag = int(np.floor((period - 1) / 2))
    lag_series = series.shift(lag)
    zlema_series = (2 * series - lag_series).ewm(span=period, adjust=False).mean()
    return zlema_series

# --- Define DEMA ---
def dema(series, period):
    ema1 = series.ewm(span=period, adjust=False).mean()
    ema2 = ema1.ewm(span=period, adjust=False).mean()
    return 2 * ema1 - ema2

# --- Define T3 ---
def t3(series, period, vfactor=0.7):
    e1 = series.ewm(span=period, adjust=False).mean()
    e2 = e1.ewm(span=period, adjust=False).mean()
    e3 = e2.ewm(span=period, adjust=False).mean()
    e4 = e3.ewm(span=period, adjust=False).mean()
    e5 = e4.ewm(span=period, adjust=False).mean()
    e6 = e5.ewm(span=period, adjust=False).mean()
    c1 = -vfactor ** 3
    c2 = 3 * (vfactor ** 2 + vfactor ** 3)
    c3 = -3 * (vfactor + vfactor ** 2 + vfactor ** 3)
    c4 = 1 + 3 * vfactor + vfactor ** 3 + 3 * vfactor ** 2
    return c1 * e6 + c2 * e5 + c3 * e4 + c4 * e3

# --- Example Kalman filter (simple) ---
def kalman_filter(series):
    n = len(series)
    Q = 1e-5  # process variance
    xhat = np.zeros(n)
    P = np.zeros(n)
    xhatminus = np.zeros(n)
    Pminus = np.zeros(n)
    K = np.zeros(n)
    xhat[0] = series.iloc[0]
    P[0] = 1.0
    for k in range(1, n):
        xhatminus[k] = xhat[k-1]
        Pminus[k] = P[k-1] + Q
        K[k] = Pminus[k] / (Pminus[k] + 1)
        xhat[k] = xhatminus[k] + K[k] * (series.iloc[k] - xhatminus[k])
        P[k] = (1 - K[k]) * Pminus[k]
    return pd.Series(xhat, index=series.index)

# --- Loop by Business Group ---
for g in groups:
    grp = df[df['BUSINESS_GROUPS_TA'] == g].copy().set_index('PERIOD').sort_index()

    # Smoothing calculations
    grp['SMA'] = grp['NEW_OPENINGS_COUNT'].rolling(window=ROLL_WINDOW).mean()
    grp['EMA'] = grp['NEW_OPENINGS_C]()






import pandas as pd

# --- Example: df1 already loaded ---
# df1 = pd.read_excel('monthwise_updated_attrition_dataset.xlsx')

# --- Step 1: Convert MONTH from YYYY-MM to YYYYMM format ---
df1['MONTH_YYYYMM'] = pd.to_datetime(df1['MONTH']).dt.strftime('%Y%m').astype(int)

# --- Step 2: Filter only the columns we need (MONTH + HEADCOUNT) ---
df_headcount = df1[['MONTH_YYYYMM', 'HEADCOUNT']]

# --- Step 3: Assume grouped_df already loaded ---
# grouped_df has a column 'MONTH' in YYYYMM format
# Make sure its MONTH column is also int
grouped_df['MONTH'] = grouped_df['MONTH'].astype(int)

# --- Step 4: Left join on MONTH ---
merged_df = pd.merge(
    grouped_df,
    df_headcount,
    how='left',
    left_on='MONTH',
    right_on='MONTH_YYYYMM'
)

# --- Step 5: Drop helper column if needed ---
merged_df.drop(columns=['MONTH_YYYYMM'], inplace=True)

# --- Check ---
print(merged_df.head())





import pandas as pd

# assuming your dataframe is named dft as in the screenshot
# Group by PERIOD and BUSINESS_GROUPS_TA, summing the OPENINGS_AVAILABLE_EX_CAMP
grouped_df = (
    dft
    .groupby(['PERIOD', 'BUSINESS_GROUPS_TA'], as_index=False)['OPENINGS_AVAILABLE_EX_CAMP']
    .sum()
    .rename(columns={'OPENINGS_AVAILABLE_EX_CAMP': 'NEW_OPENINGS_COUNT'})
)

# This will give you total new openings per period per business group
print(grouped_df.head())






1️⃣ What the plot is showing

Each node (circle) = a business group.

Node size = CURRENT_HEADCOUNT — bigger circle = more employees.

Node color (red shade) = attrition_frac — darker red = higher voluntary attrition rate.

Lines between nodes (edges) = similarity of risk profiles between business groups (based on attrition + error %).

Edge thickness = how strongly similar they are.



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

COL_BUS = 'BUSINESS_GROUPS'
COL_HC = 'CURRENT_HEADCOUNT'
COL_PROJ_EXIST = 'PROJECTED_VOL'
COL_PROJ_NEW = 'New Projected Vol'
COL_ACTUAL_VOL = 'Actual Vol Terms'
COL_PROJ_HC = 'PROJECTED_HEADCOUNT'
COL_PROJ_HC_NEW = 'New Projected Headcount'
COL_ACTUAL_HC_JUNE = 'Actual Headcount June'
COL_PCT_NEW_VS_ACT = '% (new) Vs Actuals'

df = pd.read_csv("your_input.csv")

# -----------------------------
# 1. Attrition Funnel
# -----------------------------
totals = {
    "Current HC": df[COL_HC].sum(),
    "Proj Exits (Exist)": df[COL_PROJ_EXIST].sum(),
    "Proj Exits (New)": df[COL_PROJ_NEW].sum(),
    "Actual Exits": df[COL_ACTUAL_VOL].sum(),
}
plt.figure(figsize=(8,6))
plt.plot(list(totals.keys()), list(totals.values()), marker="o", linewidth=3, color="teal")
plt.fill_between(list(totals.keys()), list(totals.values()), alpha=0.2, color="teal")
plt.title("Attrition Funnel: Headcount → Projections → Actuals")
plt.ylabel("Headcount")
plt.tight_layout()
plt.savefig("funnel_attrition.png")
plt.close()

# -----------------------------
# 2. Radar Chart (per Business Group)
# -----------------------------
import math

groups = df[COL_BUS].unique()[:6]  # top 6 groups for clarity
labels = ["Proj Exist", "Proj New", "Actual"]

angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()
angles += angles[:1]

plt.figure(figsize=(6,6))
ax = plt.subplot(111, polar=True)
for g in groups:
    vals = df.loc[df[COL_BUS]==g, [COL_PROJ_EXIST, COL_PROJ_NEW, COL_ACTUAL_VOL]].values.flatten().tolist()
    vals += vals[:1]
    ax.plot(angles, vals, label=g, linewidth=2)
    ax.fill(angles, vals, alpha=0.15)

ax.set_xticks(angles[:-1])
ax.set_xticklabels(labels)
plt.title("Radar Chart: Projections vs Actual (Sample Groups)")
plt.legend(bbox_to_anchor=(1.1,1.05))
plt.tight_layout()
plt.savefig("radar_projection.png")
plt.close()

# -----------------------------
# 3. Accuracy Gauge (Speedometer)
# -----------------------------
ema_err = abs(df[COL_PROJ_NEW].sum() - df[COL_ACTUAL_VOL].sum())
exist_err = abs(df[COL_PROJ_EXIST].sum() - df[COL_ACTUAL_VOL].sum())

ema_acc = max(0, 100 - (ema_err/df[COL_ACTUAL_VOL].sum()*100))
exist_acc = max(0, 100 - (exist_err/df[COL_ACTUAL_VOL].sum()*100))

fig, ax = plt.subplots(figsize=(6,3), subplot_kw={'projection':'polar'})
theta = np.linspace(-np.pi/2, np.pi/2, 100)
r = np.ones_like(theta)
ax.plot(theta, r, linewidth=10, color="lightgray")

# EMA pointer
ax.plot([(-np.pi/2)+(ema_acc/100*np.pi)], [1], marker="o", markersize=15, color="green")
# Existing pointer
ax.plot([(-np.pi/2)+(exist_acc/100*np.pi)], [1], marker="o", markersize=15, color="red")

ax.set_rticks([]); ax.set_xticks([])
ax.set_yticklabels([]); ax.set_xticklabels([])
plt.title(f"Prediction Accuracy: EMA {ema_acc:.1f}% | Existing {exist_acc:.1f}%")
plt.tight_layout()
plt.savefig("accuracy_gauge.png")
plt.close()

# -----------------------------
# 4. Treemap of Attrition
# -----------------------------
import squarify

sizes = df[COL_HC]
colors = df[COL_PCT_NEW_VS_ACT]
labels = [f"{b}\nHC:{hc}\nErr:{err:.1f}%" for b,hc,err in zip(df[COL_BUS], sizes, colors)]

plt.figure(figsize=(12,8))
squarify.plot(sizes=sizes, label=labels, color=sns.color_palette("coolwarm", len(sizes)), alpha=0.8)
plt.axis("off")
plt.title("Treemap: Business Groups by Headcount (colored by % error New vs Actual)")
plt.tight_layout()
plt.savefig("treemap_attrition.png")
plt.close()

# -----------------------------
# 5. Scenario Simulation Curve
# -----------------------------
base = df[COL_PROJ_NEW].sum()
actual = df[COL_ACTUAL_VOL].sum()
x = np.linspace(-20, 20, 41)  # +/- 20% deviation
y = df[COL_HC].sum() - (base * (1 + x/100))

plt.figure(figsize=(8,6))
plt.plot(x, y, color="blue", linewidth=2)
plt.axvline(0, color="gray", linestyle="--")
plt.axhline(df[COL_ACTUAL_HC_JUNE].sum(), color="red", linestyle="--", label="Actual June HC")
plt.title("Scenario Simulation: Headcount Impact if Attrition deviates from EMA")
plt.xlabel("Deviation from EMA Projection (%)")
plt.ylabel("Remaining Headcount")
plt.legend()
plt.tight_layout()
plt.savefig("scenario_simulation.png")
plt.close()


























import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# -----------------------------
# Config
# -----------------------------
COL_BUS = 'BUSINESS_GROUPS'
COL_HC = 'CURRENT_HEADCOUNT'
COL_ATTR = 'VOLUNTARY_ATTRITION_RATE'
COL_PROJ_EXIST = 'PROJECTED_VOL'
COL_PROJ_NEW = 'New Projected Vol'
COL_ACTUAL_VOL = 'Actual Vol Terms'
COL_PCT_EXIST_VS_ACT = '% (Existing) Vs Actuals'
COL_PCT_NEW_VS_ACT = '% (new) Vs Actuals'
COL_PROJ_HC = 'PROJECTED_HEADCOUNT'
COL_PROJ_HC_NEW = 'New Projected Headcount'
COL_ACTUAL_HC_JUNE = 'Actual Headcount June'
COL_PROJ_EXIST_VS_JUNE = 'Projected (Existing Vs June)'
COL_PROJ_NEW_VS_JUNE = 'Projected (New Vs June)'

OUTDIR = "hr_viz_static"
os.makedirs(OUTDIR, exist_ok=True)

# -----------------------------
# Load data
# -----------------------------
df = pd.read_csv("your_input.csv")

# -----------------------------
# KPI summary (big picture bar chart)
# -----------------------------
totals = {
    "Existing Projection": df[COL_PROJ_EXIST].sum(),
    "New (EMA) Projection": df[COL_PROJ_NEW].sum(),
    "Actual Terms": df[COL_ACTUAL_VOL].sum()
}
plt.figure(figsize=(8,5))
sns.barplot(x=list(totals.keys()), y=list(totals.values()), palette="Set2")
plt.title("Overall Attrition Terms: Existing vs EMA vs Actual")
plt.ylabel("Headcount")
plt.tight_layout()
plt.savefig(f"{OUTDIR}/kpi_summary.png")
plt.close()

# -----------------------------
# Business group comparison (clustered bars)
# -----------------------------
df_group = df[[COL_BUS, COL_PROJ_EXIST, COL_PROJ_NEW, COL_ACTUAL_VOL]].set_index(COL_BUS)
df_group.plot(kind="bar", figsize=(12,6))
plt.title("Business Group: Projected vs Actual Attrition")
plt.ylabel("Headcount")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.savefig(f"{OUTDIR}/group_comparison.png")
plt.close()

# -----------------------------
# Prediction error heatmap
# -----------------------------
df["Error_New"] = df[COL_PROJ_NEW] - df[COL_ACTUAL_VOL]
df["Error_Exist"] = df[COL_PROJ_EXIST] - df[COL_ACTUAL_VOL]

err_mat = df[[COL_BUS, "Error_New", "Error_Exist"]].set_index(COL_BUS)
plt.figure(figsize=(10,6))
sns.heatmap(err_mat, annot=True, fmt=".0f", cmap="coolwarm", center=0)
plt.title("Prediction Error Heatmap (Projection - Actual)")
plt.tight_layout()
plt.savefig(f"{OUTDIR}/prediction_error_heatmap.png")
plt.close()

# -----------------------------
# Pareto chart for EMA projections
# -----------------------------
df_pareto = df.groupby(COL_BUS)[COL_PROJ_NEW].sum().sort_values(ascending=False)
cum_pct = df_pareto.cumsum() / df_pareto.sum() * 100

fig, ax1 = plt.subplots(figsize=(12,6))
df_pareto.plot(kind="bar", ax=ax1, color="skyblue")
ax1.set_ylabel("New Projected Vol")
ax2 = ax1.twinx()
cum_pct.plot(ax=ax2, color="red", marker="o")
ax2.set_ylabel("Cumulative %")
plt.title("Pareto Analysis: New Projected Vol (EMA)")
plt.tight_layout()
plt.savefig(f"{OUTDIR}/pareto_new_proj.png")
plt.close()

# -----------------------------
# Risk scatter (quadrant style)
# -----------------------------
plt.figure(figsize=(8,6))
x = df[COL_ATTR]*100
y = df[COL_PCT_NEW_VS_ACT]
sizes = df[COL_HC]/df[COL_HC].max()*1000
plt.scatter(x, y, s=sizes, alpha=0.6, c="teal", edgecolor="k")

# quadrant lines
plt.axhline(y.median(), color="gray", linestyle="--")
plt.axvline(x.median(), color="gray", linestyle="--")

for i, row in df.iterrows():
    plt.text(row[COL_ATTR]*100, row[COL_PCT_NEW_VS_ACT], row[COL_BUS], fontsize=8)

plt.xlabel("Voluntary Attrition Rate (%)")
plt.ylabel("% (New) Vs Actuals")
plt.title("Risk Quadrant: Attrition vs Prediction Gap")
plt.tight_layout()
plt.savefig(f"{OUTDIR}/risk_quadrant.png")
plt.close()

# -----------------------------
# Distribution of % error
# -----------------------------
plt.figure(figsize=(8,6))
sns.violinplot(y=df[COL_PCT_NEW_VS_ACT], inner="box", color="lightblue")
sns.swarmplot(y=df[COL_PCT_NEW_VS_ACT], color="k", size=4)
plt.title("Distribution of % (New) Vs Actuals")
plt.ylabel("Prediction Error %")
plt.tight_layout()
plt.savefig(f"{OUTDIR}/error_distribution.png")
plt.close()

print(f"All static figures saved in: {OUTDIR}")




























# Copy-paste this cell into Jupyter and run (make sure df is loaded with the exact columns you listed)
import pandas as pd
import numpy as np
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity

# ---------- Helpers to parse input columns robustly ----------
def to_fraction(col):
    ser = pd.Series(col).astype(str).str.replace('%','').str.replace(',','').str.strip()
    num = pd.to_numeric(ser, errors='coerce').fillna(0.0)
    if (num.max() > 1.5):
        num = num / 100.0
    return num

def to_percent_number(col):
    ser = pd.Series(col).astype(str).str.replace('%','').str.replace(',','').str.strip()
    num = pd.to_numeric(ser, errors='coerce').fillna(0.0)
    if (num.max() <= 1.5):
        num = num * 100.0
    return num

# ---------- Core function ----------
def interpret_attrition_network(df,
                                sim_threshold=0.9,
                                headcount_pctile=75,
                                attrition_pctile=75,
                                error_pctile=75,
                                verbose=True):
    """
    Build similarity graph from (attrition_frac, new_error_pct), compute metrics,
    and produce CEO-level interpretation per group and per-cluster tables.

    Inputs:
      - df: dataframe with the exact columns you provided.
      - sim_threshold: cosine similarity threshold to create an edge between groups.
      - headcount_pctile / attrition_pctile / error_pctile: percentiles used to detect 'high' flags.
    Returns:
      - group_table (DataFrame): one row per BUSINESS_GROUPS with metrics, flags, suggested_action, exec_summary
      - cluster_table (DataFrame): per-cluster aggregated summary and recommended action
    """
    # Required columns (exact names)
    req = [
        'BUSINESS_GROUPS','CURRENT_HEADCOUNT','VOLUNTARY_ATTRITION_RATE',
        'New Projected Vol','Actual Vol Terms','PROJECTED_VOL',
        '% (Existing) Vs Actuals','% (new) Vs Actuals',
        'PROJECTED_HEADCOUNT','New Projected Headcount','Actual Headcount June',
        'Projected (Existing Vs June)','Projected (New Vs June)'
    ]
    miss = [c for c in req if c not in df.columns]
    if miss:
        raise ValueError("Missing required columns (exact names): " + ", ".join(miss))

    d = df.copy()

    # Parse numeric fields we will use
    d['CURRENT_HEADCOUNT'] = pd.to_numeric(d['CURRENT_HEADCOUNT'], errors='coerce').fillna(0.0)
    d['attrition_frac'] = to_fraction(d['VOLUNTARY_ATTRITION_RATE'])
    d['new_error_pct'] = to_percent_number(d['% (new) Vs Actuals']).fillna(0.0)    # percent (e.g. 5.0)
    d['existing_error_pct'] = to_percent_number(d['% (Existing) Vs Actuals']).fillna(0.0)
    d['attrition_count_expected'] = (d['CURRENT_HEADCOUNT'] * d['attrition_frac']).round(1)
    d['net_change_new_vs_june'] = d['New Projected Headcount'].astype(float) - d['Actual Headcount June'].astype(float)
    d['abs_new_error_pct'] = d['new_error_pct'].abs()

    # Build similarity graph on (attrition_frac, new_error_pct)
    features = np.vstack([d['attrition_frac'].astype(float), d['new_error_pct'].astype(float)]).T
    sim = cosine_similarity(features)
    np.fill_diagonal(sim, 0.0)

    G = nx.Graph()
    for i, gname in enumerate(d['BUSINESS_GROUPS']):
        G.add_node(gname,
                   headcount=float(d.loc[i, 'CURRENT_HEADCOUNT']),
                   attrition=float(d.loc[i, 'attrition_frac']),
                   new_error=float(d.loc[i, 'new_error_pct']))

    # add edges where similarity > threshold
    n = len(d)
    for i in range(n):
        for j in range(i+1, n):
            if sim[i, j] >= sim_threshold:
                G.add_edge(d.loc[i, 'BUSINESS_GROUPS'], d.loc[j, 'BUSINESS_GROUPS'], weight=float(sim[i,j]))

    # Graph metrics
    degree = dict(G.degree())
    # weighted degree = sum of weights of edges incident on node (use 0 if no edges)
    weighted_degree = {}
    for node in G.nodes():
        s = 0.0
        for nbr in G.neighbors(node):
            s += G.edges[node, nbr].get('weight', 1.0)
        weighted_degree[node] = s
    deg_cent = nx.degree_centrality(G) if G.number_of_nodes()>0 else {n:0 for n in G.nodes()}
    btw = nx.betweenness_centrality(G) if G.number_of_nodes()>0 else {n:0 for n in G.nodes()}
    cls = nx.closeness_centrality(G) if G.number_of_nodes()>0 else {n:0 for n in G.nodes()}

    # Cluster / connected component analysis
    components = list(nx.connected_components(G))
    # Map node -> comp_id
    node2comp = {}
    comp_summaries = []
    for cid, comp in enumerate(components, start=1):
        comp_nodes = list(comp)
        comp_headcount = sum([G.nodes[n]['headcount'] for n in comp_nodes])
        comp_attr = np.mean([G.nodes[n]['attrition'] for n in comp_nodes])
        comp_error = np.mean([G.nodes[n]['new_error'] for n in comp_nodes])
        comp_summaries.append({
            'cluster_id': cid,
            'n_groups': len(comp_nodes),
            'groups': comp_nodes,
            'total_headcount': comp_headcount,
            'avg_attrition_frac': comp_attr,
            'avg_new_error_pct': comp_error
        })
        for n in comp_nodes:
            node2comp[n] = cid
    # Nodes not in any component (isolated nodes) become single-node clusters
    isolated = [n for n in G.nodes() if n not in node2comp]
    for iso in isolated:
        cid = len(comp_summaries) + 1
        node2comp[iso] = cid
        comp_summaries.append({
            'cluster_id': cid,
            'n_groups': 1,
            'groups': [iso],
            'total_headcount': G.nodes[iso]['headcount'],
            'avg_attrition_frac': G.nodes[iso]['attrition'],
            'avg_new_error_pct': G.nodes[iso]['new_error']
        })

    # Build per-group table
    rows = []
    # thresholds using percentiles (plus sensible minimums)
    headcount_high_thresh = np.percentile(d['CURRENT_HEADCOUNT'], headcount_pctile)
    attrition_high_thresh = max(np.percentile(d['attrition_frac'], attrition_pctile), 0.07)  # at least 7%
    error_high_thresh = np.percentile(d['abs_new_error_pct'], error_pctile)

    # For composite risk score: normalize three signals
    def minmax(s):
        if s.max()==s.min():
            return (s*0.0)
        return (s - s.min()) / (s.max() - s.min())

    norm_attr = minmax(d['attrition_frac'])
    norm_head = minmax(d['CURRENT_HEADCOUNT'])
    norm_err  = minmax(d['abs_new_error_pct'])
    composite = 0.55*norm_attr + 0.35*norm_head + 0.10*norm_err

    for i, row in d.iterrows():
        name = row['BUSINESS_GROUPS']
        hc = float(row['CURRENT_HEADCOUNT'])
        attr = float(row['attrition_frac'])
        attr_pct = attr * 100.0
        err = float(row['new_error_pct'])
        deg = degree.get(name, 0)
        wdeg = weighted_degree.get(name, 0.0)
        dc = deg_cent.get(name, 0.0)
        bw = btw.get(name, 0.0)
        cl = cls.get(name, 0.0)
        comp_id = node2comp.get(name, None)
        comp_info = next((c for c in comp_summaries if c['cluster_id']==comp_id), None)

        # flags
        is_large = hc >= headcount_high_thresh
        is_high_attr = attr >= attrition_high_thresh
        is_high_error = abs(err) >= error_high_thresh
        is_high_degree = deg >= np.percentile(list(degree.values()) if degree else [0], 75) if degree else False

        # suggested action rules (simple template)
        actions = []
        if is_large and is_high_attr:
            actions.append("Immediate retention program & leadership review")
            actions.append("Comp/benefits audit for this group")
        elif is_large and is_high_error:
            actions.append("Model review & local forecast adjustment (large group)")
        elif is_high_attr:
            actions.append("Targeted retention actions (stay interviews, incentives)")
        elif is_high_error:
            actions.append("Model tuning: EMA under/over-performs; investigate drivers")
        else:
            actions.append("Monitor; maintain current programs")

        # cluster-level augmentation
        if comp_info and comp_info['avg_attrition_frac'] >= attrition_high_thresh and comp_info['n_groups']>1:
            actions.append("Cluster-level intervention recommended (systemic driver likely)")

        # centrality advice
        if dc >= np.percentile(list(dc for dc in deg_cent.values()) if deg_cent else [0], 75):
            actions.append("High centrality: stabilizing this group can reduce system risk")

        suggested_action = " / ".join(actions)

        # auto-generated CEO-level sentence (concise)
        neighbors = list(G.neighbors(name)) if name in G.nodes() else []
        neighbor_text = ""
        if neighbors:
            neighbor_text = f" Similar groups: {', '.join(neighbors[:4]) + ('...' if len(neighbors)>4 else '')}."
        cluster_text = ""
        if comp_info:
            cluster_text = f" Part of cluster #{comp_id} (size={comp_info['n_groups']}, total HC={int(comp_info['total_headcount'])})."
        exec_summary = (f"{name}: {('LARGE' if is_large else 'SMALLER')} team (HC={int(hc)}), "
                        f"attrition ~ {attr_pct:.1f}%. Model error ~ {err:.1f}%.{neighbor_text}{cluster_text} "
                        f"Recommended: {suggested_action}.")

        rows.append({
            'BUSINESS_GROUPS': name,
            'CURRENT_HEADCOUNT': int(hc),
            'Attrition_pct': attr_pct,
            'New_error_pct': err,
            'Degree': deg,
            'Weighted_degree': round(wdeg, 3),
            'Degree_centrality': round(dc, 3),
            'Betweenness': round(bw, 4),
            'Cluster_id': comp_id,
            'Cluster_size': comp_info['n_groups'] if comp_info else 1,
            'Cluster_total_headcount': int(comp_info['total_headcount']) if comp_info else int(hc),
            'Is_large_headcount': bool(is_large),
            'Is_high_attrition': bool(is_high_attr),
            'Is_high_error': bool(is_high_error),
            'Composite_risk': round(float(composite.iloc[i]), 3),
            'Suggested_action': suggested_action,
            'Exec_summary': exec_summary
        })

    group_table = pd.DataFrame(rows).sort_values('Composite_risk', ascending=False).reset_index(drop=True)

    # Build cluster summary table
    crows = []
    for c in comp_summaries:
        cid = c['cluster_id']
        avg_attr_pct = c['avg_attrition_frac']*100.0
        avg_err = c['avg_new_error_pct']
        rec = "Cluster-level review" if (c['avg_attrition_frac'] >= attrition_high_thresh and c['n_groups']>1) else "No cluster alarm"
        # escalate if very large cluster headcount
        if c['total_headcount'] >= np.percentile(d['CURRENT_HEADCOUNT'], 75):
            rec += " / High-impact cluster"
        crows.append({
            'cluster_id': cid,
            'n_groups': c['n_groups'],
            'groups': ", ".join(c['groups']),
            'total_headcount': int(c['total_headcount']),
            'avg_attrition_pct': round(avg_attr_pct, 2),
            'avg_new_error_pct': round(avg_err, 2),
            'recommended_action': rec
        })
    cluster_table = pd.DataFrame(crows).sort_values('total_headcount', ascending=False).reset_index(drop=True)

    # Top-level textual executive summary
    top_by_risk = group_table.head(5)
    top_list = "; ".join([f"{r['BUSINESS_GROUPS']} (HC={r['CURRENT_HEADCOUNT']}, Attr={r['Attrition_pct']:.1f}%)" for _, r in top_by_risk.iterrows()])

    overall_summary = (
        f"Executive Summary:\n"
        f"- Top risk groups (by composite score): {top_list}.\n"
        f"- Number of detected clusters (connected groups): {len(comp_summaries)}. "
        f"{sum(1 for c in comp_summaries if c['avg_attrition_frac']>=attrition_high_thresh)} clusters have above-threshold attrition.\n"
        f"- Thresholds used: headcount >= {int(headcount_high_thresh)} (>= {headcount_pctile}th pct), "
        f"attrition >= {attrition_high_thresh:.2%}, error >= {error_high_thresh:.2f}%.\n"
        f"- Immediate recommended actions: prioritize the big & high-attrition groups for retention programs and leadership reviews; "
        f"investigate groups where the new model error is high (model tuning/local adjustments)."
    )

    if verbose:
        print(overall_summary)
        print("\nTop 10 groups with suggested action (first 10 rows):\n")
        display(group_table.head(10))
        print("\nCluster summary:\n")
        display(cluster_table)

    return group_table, cluster_table

# ---------- Example usage ----------
# group_table, cluster_table = interpret_attrition_network(df, sim_threshold=0.9)
# group_table.to_csv('attrition_group_interpretation.csv', index=False)
# cluster_table.to_csv('attrition_cluster_summary.csv', index=False)























# Robust Network Graph with reliable colorbar (use in Jupyter)
import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import matplotlib as mpl
from sklearn.metrics.pairwise import cosine_similarity

# ---------- (OPTIONAL) sample df for quick test ----------
# Comment out if you already have df loaded
# df = pd.DataFrame({
#     'BUSINESS_GROUPS': ['A','B','C','D'],
#     'CURRENT_HEADCOUNT': [120, 45, 300, 80],
#     'attrition_frac': [0.07, 0.12, 0.03, 0.20],
#     'new_error_pct': [5.0, 12.0, 3.0, 8.0]
# })

# ---------- Validate df columns ----------
req = ['BUSINESS_GROUPS','CURRENT_HEADCOUNT','attrition_frac','new_error_pct']
missing = [c for c in req if c not in df.columns]
if missing:
    raise ValueError("Missing required columns in df: " + ", ".join(missing))

# ---------- Compute pairwise similarity and build graph ----------
features = np.c_[df['attrition_frac'].astype(float), df['new_error_pct'].astype(float)]
sim = cosine_similarity(features)
np.fill_diagonal(sim, 0.0)
threshold = 0.9  # tweak as needed

G = nx.Graph()
for i, gname in enumerate(df['BUSINESS_GROUPS']):
    G.add_node(gname,
               size=float(df['CURRENT_HEADCOUNT'].iloc[i]),
               color=float(df['attrition_frac'].iloc[i]) )

for i in range(len(df)):
    for j in range(i+1, len(df)):
        if sim[i, j] > threshold:
            G.add_edge(df['BUSINESS_GROUPS'].iloc[i],
                       df['BUSINESS_GROUPS'].iloc[j],
                       weight=float(sim[i, j]))

if G.number_of_nodes() == 0:
    raise RuntimeError("Graph has no nodes (check df).")

# ---------- Layout and drawing ----------
fig, ax = plt.subplots(figsize=(10, 8))
pos = nx.spring_layout(G, k=0.5, seed=42)  # reproducible layout

# node sizes and colors
nodes_list = list(G.nodes())
sizes = [G.nodes[n]['size'] * 5 for n in nodes_list]   # scale factor
colors = [G.nodes[n]['color'] for n in nodes_list]

# fix degenerate vmin/vmax
vmin = min(colors)
vmax = max(colors)
if np.isclose(vmin, vmax):
    vmin = vmin - 1e-3
    vmax = vmax + 1e-3

# draw nodes (use draw_networkx_nodes which returns a PathCollection)
nodes_pc = nx.draw_networkx_nodes(G, pos,
                                  nodelist=nodes_list,
                                  node_size=sizes,
                                  node_color=colors,
                                  cmap='Reds',
                                  vmin=vmin,
                                  vmax=vmax,
                                  ax=ax)
nx.draw_networkx_labels(G, pos, ax=ax, font_size=10)
# draw edges with width proportional to weight (if present)
if G.number_of_edges() > 0:
    widths = [G[u][v].get('weight', 0.2) * 3.0 for u, v in G.edges()]
    nx.draw_networkx_edges(G, pos, ax=ax, edge_color='gray', width=widths, alpha=0.7)

ax.set_title("Business Group Risk Map (size=headcount, color=attrition%)")
ax.axis('off')

# ---------- Add colorbar robustly ----------
try:
    # preferred: create ScalarMappable with same cmap and norm then attach to the figure
    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)
    sm = mpl.cm.ScalarMappable(cmap=mpl.cm.get_cmap('Reds'), norm=norm)
    # set_array must be non-empty to avoid ambiguous mappable behavior in some backends
    sm.set_array(np.asarray(colors))
    # attach colorbar to the figure, specifying the axis to steal space from
    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label('Attrition Fraction')
except Exception as e:
    # fallback: use scatter + colorbar (more explicit mappable)
    print("Primary colorbar method failed, using fallback scatter-based colorbar. Error:", e)
    xs = [pos[n][0] for n in nodes_list]
    ys = [pos[n][1] for n in nodes_list]
    sc = ax.scatter(xs, ys, s=sizes, c=colors, cmap='Reds', vmin=vmin, vmax=vmax)
    cbar = fig.colorbar(sc, ax=ax, fraction=0.046, pad=0.04)
    cbar.set_label('Attrition Fraction')

plt.show()























import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib as mpl

# Example dummy df (replace with your real df)
# df = pd.DataFrame({
#     'BUSINESS_GROUPS':['A','B','C'],
#     'CURRENT_HEADCOUNT':[100,200,150],
#     'attrition_frac':[0.1,0.25,0.4],
#     'new_error_pct':[0.05,0.2,0.1]
# })

# 1️⃣ Compute similarity matrix
features = np.c_[df['attrition_frac'], df['new_error_pct']]
sim = cosine_similarity(features)
np.fill_diagonal(sim, 0)
threshold = 0.9

# 2️⃣ Build Graph
G = nx.Graph()
for i, g in enumerate(df['BUSINESS_GROUPS']):
    G.add_node(
        g,
        size=df['CURRENT_HEADCOUNT'].iloc[i],
        color=df['attrition_frac'].iloc[i]
    )

for i in range(len(df)):
    for j in range(i + 1, len(df)):
        if sim[i, j] > threshold:
            G.add_edge(df['BUSINESS_GROUPS'].iloc[i],
                       df['BUSINESS_GROUPS'].iloc[j],
                       weight=sim[i, j])

# 3️⃣ Prepare node attributes
pos = nx.spring_layout(G, k=0.5)
sizes = [G.nodes[n]['size'] * 5 for n in G.nodes()]
colors = [G.nodes[n]['color'] for n in G.nodes()]

# 4️⃣ Draw graph
plt.figure(figsize=(10, 8))
nodes = nx.draw_networkx_nodes(G, pos, node_size=sizes,
                               node_color=colors, cmap=plt.cm.Reds)
nx.draw_networkx_labels(G, pos)
nx.draw_networkx_edges(G, pos, edge_color='gray')

plt.title("Business Group Risk Map (size=headcount, color=attrition%)")

# 5️⃣ Add colorbar properly
norm = mpl.colors.Normalize(vmin=min(colors), vmax=max(colors))
sm = mpl.cm.ScalarMappable(cmap=plt.cm.Reds, norm=norm)
sm.set_array([])  # needed for colorbar
cbar = plt.colorbar(sm)
cbar.set_label('Attrition Fraction')

plt.show()
